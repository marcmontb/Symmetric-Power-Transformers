{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcmontb/Symmetric-Power-Transformers/blob/main/3_0_Notebook_Adaptive_Symmetric_Power_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYBESd-CEToN"
      },
      "source": [
        "# Adaptive Symmetric Power Transformers\n",
        "\n",
        "The Adaptive Symmetric Power Transformer (ASPT) is a theoretical twist on the Symmetric Power Transformer (SPT) idea. The original SPT, introduced by Manifest AI, made transformers more efficient by using a power function instead of the usual softmax, and later formulating them as Linear Transformers using Symmetric Power Embeddings. Our ASPT concept takes this a step further. We're exploring what happens if we let the power change based on the input, rather than keeping it fixed. This could help the model adapt better to different parts of a sequence, potentially capturing more complex patterns. In this write-up, we'll look at how this idea might work, what challenges it brings, and what it could mean for language processing tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahFxIxgUkQrT"
      },
      "source": [
        "# 1. Adaptive Power Mechanism\n",
        "\n",
        "\n",
        "The Adaptive Symmetric Power Transformer introduces a dynamic, input-dependent power parameter through an adaptive power network. For an input vector $x \\in \\mathbb{R}^{d_{model}}$, the adaptive power network $f_\\theta: \\mathbb{R}^{d_{model}} \\to \\mathbb{R}$ is defined as:\n",
        "\n",
        "$$f_\\theta(x) = \\sigma(W_2 \\cdot \\text{ReLU}(W_1x + b_1) + b_2)$$\n",
        "\n",
        "where $W_1 \\in \\mathbb{R}^{d_{model} \\times d_{model}}$, $W_2 \\in \\mathbb{R}^{d_{model} \\times 1}$, $b_1 \\in \\mathbb{R}^{d_{model}}$, $b_2 \\in \\mathbb{R}$ are learnable parameters, ReLU is the rectified linear unit function, and $\\sigma$ is the sigmoid function. The final adaptive power $p(x)$ is computed as:\n",
        "\n",
        "$$p(x) = p_{min} + (p_{max} - p_{min}) \\cdot f_\\theta(x)$$\n",
        "\n",
        "This formulation ensures that $p(x) \\in (p_{min}, p_{max})$, allowing the model to dynamically adjust its behavior within a predefined range. Typically, $p_{min}$ and $p_{max}$ are set to even integers, maintaining consistency with the theoretical foundations of Symmetric Power Transformers.\n",
        "\n",
        "In the current implementation, this adaptive power is computed only for the query vectors in the attention mechanism, introducing an asymmetry that diverges from traditional attention formulations. This design choice may lead to interesting dynamics in how the model processes and attends to different parts of the input sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIkqa0WfcVOM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnn18EaWlAHE"
      },
      "outputs": [],
      "source": [
        "class AdaptivePowerNetwork(nn.Module):\n",
        "    def __init__(self, d_model, p_min=2, p_max=8):\n",
        "        super().__init__()\n",
        "        self.p_min = p_min\n",
        "        self.p_max = p_max\n",
        "        self.p_network = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        p_scale = self.p_network(x).squeeze(-1)\n",
        "        p = self.p_min + (self.p_max - self.p_min) * p_scale\n",
        "        return p\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIF0h0PinBfi"
      },
      "source": [
        "The `p_network` corresponds to $f_\\theta$, and the final computation of `p` matches the equation for $p(x)$. The use of `nn.Sequential` allows for a compact representation of the two-layer network with ReLU activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABmSnpqNludh"
      },
      "source": [
        "# 2. Symmetric Power Embedding\n",
        "\n",
        "The cornerstone of the Symmetric Power Transformer is the symmetric power embedding, which we extend to incorporate the adaptive power mechanism. For a vector $v \\in \\mathbb{R}^d$ and a power $p \\in \\mathbb{R}^+$, the symmetric power embedding $\\phi_p(v)$ is implemented as:\n",
        "\n",
        "$$\\phi_p(v) = (\\sqrt{c_\\alpha} \\prod_{i=1}^{\\lfloor p \\rfloor} v_{\\alpha_i})_{\\alpha \\in I_{d,\\lfloor p \\rfloor}}$$\n",
        "\n",
        "where $I_{d,\\lfloor p \\rfloor}$ is the set of non-decreasing multi-indices of length $\\lfloor p \\rfloor$ with entries in $\\{1, ..., d\\}$, and $c_\\alpha$ is the multinomial coefficient accounting for repeated indices in $\\alpha$. The floor function $\\lfloor p \\rfloor$ is used to handle non-integer power values produced by the adaptive mechanism, effectively rounding down to the nearest integer.\n",
        "\n",
        "The implementation computes this embedding for each vector in the input sequence individually, applying the corresponding adaptive power. This approach allows for fine-grained control over the embedding dimension for each input element, potentially capturing varying levels of higher-order interactions across the sequence.\n",
        "\n",
        "The dimension of the symmetric power embedding for each vector is $\\binom{d+\\lfloor p \\rfloor-1}{\\lfloor p \\rfloor}$, which grows polynomially with $p$ for fixed $d$. This growth in dimensionality presents computational challenges for large $d$ or $p$, and may require approximation techniques or hardware-specific optimizations for practical large-scale applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzJyNaecqM8F"
      },
      "outputs": [],
      "source": [
        "class SymmetricPowerEmbedding(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, p):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        # Pre-compute the output dimension for a single embedding\n",
        "        sample_embed = self.symmetric_power_embedding(x[0, 0], p[0, 0].item())\n",
        "        embed_dim = len(sample_embed)\n",
        "\n",
        "        # Initialize the output tensor with the correct shape\n",
        "        embedding = torch.zeros(\n",
        "            (batch_size * seq_len, embed_dim),\n",
        "            device=x.device,\n",
        "            dtype=x.dtype\n",
        "        )\n",
        "\n",
        "        # Fill the tensor\n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_len):\n",
        "                idx = i * seq_len + j\n",
        "                v = x[i, j]\n",
        "                p_val = p[i, j].item()\n",
        "                embedding[idx] = self.symmetric_power_embedding(v, p_val)\n",
        "\n",
        "        # Reshape to the desired output shape\n",
        "        return embedding.view(batch_size, seq_len, embed_dim)\n",
        "\n",
        "    def symmetric_power_embedding(self, v, p):\n",
        "        d = v.shape[0]\n",
        "        x = []\n",
        "        for midx in self.non_decreasing_multiindices(int(p), d):\n",
        "            c = self.count(midx, d)\n",
        "            xi = math.sqrt(self.multinomial(c))\n",
        "            for j in range(int(p)):\n",
        "                xi *= v[midx[j]]\n",
        "            x.append(xi)\n",
        "        return torch.tensor(x, device=v.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def non_decreasing_multiindices(n, max_idx, starting_from=0):\n",
        "        if n == 1:\n",
        "            return [[i] for i in range(starting_from, max_idx)]\n",
        "        seqs = []\n",
        "        for i in range(starting_from, max_idx):\n",
        "            seqs += [[i] + remainder for remainder in\n",
        "                     SymmetricPowerEmbedding.non_decreasing_multiindices(n-1, max_idx, starting_from=i)]\n",
        "        return seqs\n",
        "\n",
        "    @staticmethod\n",
        "    def multinomial(lst):\n",
        "        res, i = 1, 1\n",
        "        for a in lst:\n",
        "            for j in range(1, a + 1):\n",
        "                res *= i\n",
        "                res //= j\n",
        "                i += 1\n",
        "        return res\n",
        "\n",
        "    @staticmethod\n",
        "    def count(midx, d):\n",
        "        c = [0] * d\n",
        "        for i in midx:\n",
        "            c[i] += 1\n",
        "        return c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0oMSoZ_luUp"
      },
      "source": [
        "In the code we compute the symmetric power embedding as described in the theoretical explanation. The `symmetric_power_embedding` method corresponds to $\\phi_p(v)$, with the `non_decreasing_multiindices` method generating $I_{d,\\lfloor p \\rfloor}$, and the `multinomial` method computing $c_\\alpha$. The rounding of $p$ to the nearest integer is done using `int(p)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs4SNg8ap_tN"
      },
      "source": [
        "# 3. Adaptive Symmetric Power Attention\n",
        "\n",
        "The adaptive symmetric power attention mechanism integrates the adaptive power computation with the symmetric power embedding in a multi-head attention framework. Given query, key, and value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d_{model}}$, where $n$ is the sequence length, the attention computation proceeds as follows:\n",
        "\n",
        "1. Project inputs: $Q' = W_Q Q, K' = W_K K, V' = W_V V$, where $W_Q, W_K, W_V \\in \\mathbb{R}^{d_{model} \\times d_{model}}$ are learnable projection matrices.\n",
        "\n",
        "2. Compute adaptive powers: $p_i = p(Q'_i)$ for $i = 1, ..., n$, where $Q'_i$ is the $i$-th row of $Q'$.\n",
        "\n",
        "3. Apply symmetric power embedding: $\\tilde{Q} = \\phi_p(Q'), \\tilde{K} = \\phi_p(K')$, where the embedding is applied row-wise with the corresponding adaptive power.\n",
        "\n",
        "4. Reshape for multi-head attention: Split $\\tilde{Q}, \\tilde{K}, V'$ into $h$ heads.\n",
        "\n",
        "5. Compute attention scores: $S = \\tilde{Q}\\tilde{K}^T / \\sqrt{d_k}$, where $d_k$ is the dimension per head.\n",
        "\n",
        "6. Apply mask (if provided): $S_{ij} = -\\infty$ where mask$_{ij} = 0$.\n",
        "\n",
        "7. Apply even power normalization:\n",
        "   $$A_{ij} = \\frac{(ReLU(S_{ij}) + \\epsilon)^{p_i}}{\\sum_k (ReLU(S_{ik}) + \\epsilon)^{p_i}}$$\n",
        "   where $\\epsilon$ is a small constant for numerical stability.\n",
        "\n",
        "8. Compute attention output: $O = AV'$\n",
        "\n",
        "9. Concatenate heads and project: $Y = W_O [O_1; ...; O_h]$, where $W_O \\in \\mathbb{R}^{hd_k \\times d_{model}}$ is a learnable projection matrix.\n",
        "\n",
        "This formulation differs from standard multi-head attention in several key aspects. First, the use of symmetric power embeddings allows the model to capture higher-order interactions between query and key elements. Second, the adaptive power mechanism enables the model to adjust the \"sharpness\" of attention for each query position. Finally, the even power normalization replaces the traditional softmax, potentially altering the attention dynamics in beneficial ways.\n",
        "\n",
        "An important note is that the adaptive power is only computed for the queries, not the keys. This asymmetry in the attention mechanism is a departure from the usual formulation of attention and may lead to interesting behavioral properties of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "240FO0UCqqN-"
      },
      "outputs": [],
      "source": [
        "class AdaptiveSymmetricPowerAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, d_model)\n",
        "        self.k_proj = nn.Linear(d_model, d_model)\n",
        "        self.v_proj = nn.Linear(d_model, d_model)\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.adaptive_power = AdaptivePowerNetwork(d_model)\n",
        "        self.symmetric_power_embedding = SymmetricPowerEmbedding(d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size, seq_len, _ = q.shape\n",
        "\n",
        "        # Project inputs\n",
        "        q = self.q_proj(q)\n",
        "        k = self.k_proj(k)\n",
        "        v = self.v_proj(v)\n",
        "\n",
        "        # Compute adaptive p\n",
        "        p = self.adaptive_power(q)  # [batch_size, seq_len]\n",
        "\n",
        "        # Compute symmetric power embeddings\n",
        "        q_embed = self.symmetric_power_embedding(q, p)\n",
        "        k_embed = self.symmetric_power_embedding(k, p)\n",
        "\n",
        "        # Reshape for multi-head attention\n",
        "        q_embed = q_embed.view(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
        "        k_embed = k_embed.view(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
        "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        attn_weights = torch.matmul(q_embed, k_embed.transpose(-2, -1))\n",
        "\n",
        "        if mask is not None:\n",
        "            attn_weights = attn_weights.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        # Apply even power normalization\n",
        "        attn_weights = torch.pow(torch.relu(attn_weights) + 1e-6, p.unsqueeze(1).unsqueeze(1))\n",
        "        attn_weights = attn_weights / (attn_weights.sum(dim=-1, keepdim=True) + 1e-6)\n",
        "\n",
        "        # Apply attention to values\n",
        "        output = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Reshape and project output\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        output = self.out_proj(output)\n",
        "\n",
        "        return output, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXe7mw5Iqm0Z"
      },
      "source": [
        "The code uses the `AdaptivePowerNetwork` and `SymmetricPowerEmbedding` classes defined earlier. The even power normalization is implemented using `torch.pow` and `torch.relu`, with a small epsilon (1e-6) added for numerical stability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lc2wjekp_gu"
      },
      "source": [
        "# 4. Transformer Layer and Full Model\n",
        "\n",
        "The Adaptive Symmetric Power Transformer is composed of multiple layers, each containing the adaptive symmetric power attention mechanism followed by a feed-forward network. The full model also includes embedding layers and a final output projection.\n",
        "\n",
        "The transformer layer consists of:\n",
        "1. Multi-head Adaptive Symmetric Power Attention\n",
        "2. Layer Normalization\n",
        "3. Feed-forward Network\n",
        "4. Another Layer Normalization\n",
        "\n",
        "The full model includes:\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. Multiple Transformer Layers\n",
        "4. Final Layer Normalization\n",
        "5. Output Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkJKS4SawYRq"
      },
      "outputs": [],
      "source": [
        "class AdaptiveSymmetricPowerTransformerLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = AdaptiveSymmetricPowerAttention(d_model, num_heads)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Self-attention\n",
        "        attn_output, _ = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "class AdaptiveSymmetricPowerTransformer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, num_layers, d_ff, max_seq_length, vocab_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = self.positional_encoding(max_seq_length, d_model)\n",
        "        self.layers = nn.ModuleList([\n",
        "            AdaptiveSymmetricPowerTransformerLayer(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.final_norm = nn.LayerNorm(d_model)\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        seq_len = x.size(1)\n",
        "        x = self.embedding(x) + self.pos_encoding[:seq_len, :].to(x.device)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        x = self.output_proj(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def positional_encoding(max_seq_length, d_model):\n",
        "        pos = torch.arange(max_seq_length).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pos_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        pos_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return pos_encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEJ86oxlri_x"
      },
      "source": [
        "This implementation includes both the `AdaptiveSymmetricPowerTransformerLayer` and the full `AdaptiveSymmetricPowerTransformer` model. The layer implements the structure described in the theoretical explanation, while the full model adds input embedding, positional encoding, and output projection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcbzGcrRbhO8"
      },
      "source": [
        "# 5. Synthetic dataset example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gGW4hjFbi7Z",
        "outputId": "9b0ac0a7-6e05-41a6-ab2e-47fb917ae640"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1/10:   0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "d_model = 64\n",
        "num_heads = 4\n",
        "num_layers = 2\n",
        "d_ff = 128\n",
        "max_seq_length = 50\n",
        "vocab_size = 1000\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create a small synthetic dataset\n",
        "def create_synthetic_dataset(num_samples, seq_length, vocab_size):\n",
        "    X = torch.randint(0, vocab_size, (num_samples, seq_length))\n",
        "    y = torch.randint(0, vocab_size, (num_samples,))\n",
        "    return X, y\n",
        "\n",
        "# Create train and test datasets\n",
        "train_X, train_y = create_synthetic_dataset(1000, max_seq_length, vocab_size)\n",
        "test_X, test_y = create_synthetic_dataset(200, max_seq_length, vocab_size)\n",
        "\n",
        "train_dataset = TensorDataset(train_X, train_y)\n",
        "test_dataset = TensorDataset(test_X, test_y)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Initialize the model\n",
        "model = AdaptiveSymmetricPowerTransformer(d_model, num_heads, num_layers, d_ff, max_seq_length, vocab_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X)\n",
        "        loss = criterion(output[:, -1, :], batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            output = model(batch_X)\n",
        "            _, predicted = torch.max(output[:, -1, :], 1)\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "test_input = torch.randint(0, vocab_size, (1, max_seq_length)).to(device)\n",
        "with torch.no_grad():\n",
        "    output = model(test_input)\n",
        "    _, predicted = torch.max(output[:, -1, :], 1)\n",
        "    print(f\"Input sequence: {test_input}\")\n",
        "    print(f\"Predicted next token: {predicted.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpq2jhKelmf7"
      },
      "source": [
        "\n",
        "## 6. Conclusion and Future Directions\n",
        "\n",
        "The Adaptive Symmetric Power Transformer, as implemented, provides a ground for exploring more flexible models for sequence processing tasks. However, bridging the gap between theoretical formulation and practical implementation is still a big challenge, and this is just a first shot at it.\n",
        "\n",
        "Future research directions might include:\n",
        "\n",
        "1. Investigating the impact of computing adaptive powers for both queries and keys, and comparing it with the current query-only approach.\n",
        "2. Explore the implementation of efficient algorithms (chunked algorithm) or approximations for computing symmetric power embeddings, particularly for large $p$ or $d_{model}$.\n",
        "3. Continuous Power Approximations: Analyzing the effects of the power discretization in the symmetric power embedding, and potentially exploring continuous approximations to avoid discontinuities.\n",
        "4. Developing methods to address the computational and memory challenges associated with the symmetric power embeddings, possibly through techniques like low-rank approximations or sparse representations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ-yTofjm21w"
      },
      "source": [
        "# Annex\n",
        "\n",
        "# 1. Dimension Changes and Symmetry Properties\n",
        "\n",
        "When making the power parameter p adaptive, a natural question arises about how the symmetry properties of the embeddings are maintained across different values of p. The key insight is that while the dimension of the embedding space changes with p, the fundamental symmetry properties are preserved within each p-specific space.\n",
        "\n",
        "## 1.1 Mathematical Background\n",
        "\n",
        "For a given power p and input dimension d, the symmetric power embedding lives in a space of dimension $\\binom{d+p-1}{p}$. This follows from the theory of symmetric tensors described in Section 3.1 from the original SPT paper. The embedding $\\phi^p_\\text{SYM}(v)$ maps vectors to this space while preserving all relevant symmetries.\n",
        "\n",
        "When p changes, we move between spaces of different dimensions. For instance:\n",
        "$$\\dim(\\phi^2_\\text{SYM}) = \\frac{d^2 + d}{2}$$\n",
        "$$\\dim(\\phi^4_\\text{SYM}) = \\frac{(d+3)(d+2)(d+1)d}{24}$$\n",
        "\n",
        "## 1.2 Preservation of Symmetries\n",
        "\n",
        "Let $T^p$ be a symmetric tensor of order p. The defining property of such tensors is that for all multi-indices $\\alpha$ and permutations $\\rho \\in G_p$:\n",
        "$$T^p_\\alpha = T^p_{\\rho(\\alpha)}$$\n",
        "\n",
        "This property holds independently for each p-specific embedding space. When the adaptive mechanism changes p from $p_1$ to $p_2$, we move from one symmetric tensor space to another, each maintaining its own complete set of symmetries. No cross-space symmetry preservation is required because:\n",
        "\n",
        "1. Each p defines its own complete symmetric tensor space\n",
        "2. The symmetry properties are defined within each space\n",
        "3. The dimensions change, but the fundamental symmetric structure remains intact\n",
        "\n",
        "## 1.3 Implications\n",
        "\n",
        "This mathematical structure has several important implications:\n",
        "\n",
        "1. The attention scores maintain their theoretical properties locally (within each p-specific computation):\n",
        "   $$A_{ij} = \\frac{(Q_i^T K_j)^{p(x)}}{\\sum_{k=1}^i (Q_i^T K_j)^{p(x)}}$$\n",
        "\n",
        "2. The state size becomes dynamic:\n",
        "   $$\\text{StateSize}(p) = \\text{layer\\_n} \\cdot \\text{head\\_count} \\cdot \\binom{d+p-1}{p} \\cdot \\text{value\\_size}$$\n",
        "\n",
        "3. The efficient chunked formulation of linear transformers requires modification to handle varying dimensions.\n",
        "\n",
        "## 1.4 Open Questions\n",
        "\n",
        "Several theoretical questions remain:\n",
        "\n",
        "1. How to ensure smooth transitions between spaces of different dimensions?\n",
        "2. What is the optimal trajectory of p values during training?\n",
        "3. Can we establish theoretical bounds on the computational cost given a distribution of p values?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}